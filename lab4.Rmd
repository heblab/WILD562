---
title: 'WILD 562 Lab4 : Categorical Covariates'
author: "Mark Hebblewhite"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    number_sections: yes
    self_contained: yes
    theme: simplex
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, root.dir = '/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/lab4/new')
```

# Lab 4: Categorical Resource Selection

General introduction to the biological rationale of this lab was given in the Lab 2 and 3 lab introductions. In Lab 4, we extend the analysis of habitat use by wolves in two wolf packs from 2001-2005 in Banff National Park to multivariate analysis of categorical habitat selection using multiple logistic regressions to estimate a resource selection function (RSF) as a function of the availability of different landcover resources.  

The learning objectives of today's lab are;
1) Data management and processing - 
  a)	Process spatial landcover data and make it ready for extraction to a dataframe building on labs 1, 2 and 3.  Processing distance to high human use as well. 
  b)	Adding XY coordinates to our wolf data frame by running code from source, and then re-building a new dataframe with the new landcover and distance to high human use data attached to the wolfkde dataframe.  

2)	Review how to summarize coefficients from large numbers of models. 
3)	Conduct selection ratio’ analysis using the proportional use and availabilities of our wolfkde dataset. 
4)	Conduct categorical resource selection using logistic regression. 
5)	Gain an appreciation for the influence of changing the reference category on the model.

## Preliminaries - Loading Packages
Note I have supressed the output from loading packages to save space .
```{r load packages, include = FALSE}
#function to install and load required packages
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

#load or install these packages:
packages <- c("plyr", "ks", "adehabitatHS", "adehabitatHR", "maptools", "rgdal", "sp", "raster","ggplot2","colorRamps","rgeos")

#run function to install packages
ipak(packages)
setwd("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/lab4/new")
```

# Importing Landcover Map from an ArcGIS 

In the first activity we will learn how to import an ARCGIS file in a GRID file format, and, hence, folder with associated structure called:  Landcover/ . For more background learn about spatial data analysis in R from this great website [R spatial data analysis](http://rspatial.org/spatial/index.html)

For background, today we are going to do categorical resource selection using a typical kind of landcover model. Note that I am very specific here in my language - the use of the term landcover - for good reason.  Most wildlife ecologists have a dismal understanding of where various landcover data come from, the history of the field of landcover classification, or how or where its assumptions may affect wildlife habitat modeling. 

Most modern day 'vegetation classification maps' are actually not vegetation, but are derived based on remotely-sensed data from satellites. The most common is the LANDSAT series 1 - 7 30meter satellite data products.  This is why it is more correct to call these landcover, not vegetation, classification systems because they are based on surface reflectance values in the visible and non-visible light spectra, which include non-vegetated surfaces such as urban areas, pavement, rocks, ice, lakes, clouds ( a big problem), etc. Common examples that many of us might use here in Montana or the lower 48 are LANDFIRE, National Landcover Classification Database (NLCD), etc. 

For background, I highly recommend every ecologist who uses such remotely-sensed landcover-type data become familiar with how they are generated so that you know when and how to use them wisely.  I highly recommend this book for a gentle introduction to the field Ecological :
[Remote Sensing and GIS for Ecologists using Open Source Software](http://book.ecosens.org/content/)

In particular, the following Chapter 8: Land Cover or Image Classification Approaches

Chapter 8 explains how to conduct image classification: classification principles, classification types (un-supervised and supervised approaches), and usage in real-world examples: land cover vs. land use classification will be discussed, as well as practical examples of collecting training samples, generating a landcover classification using R, evaluating a land cover classification (accuracy assessment, statistics) and accuracy assessment of classification results.

Moreover, I have also included as background reading an early seminal paper by a colleague of mine, Greg McDermid (now a professor in Geomatics at University of Calgary) that provides the average ecologist a good general background.  Later this semester, Remote sensing expert Dr. John Kimball will come and share some basic background as well as insights from the cutting edge to our class. 

_References_

Hebblewhite, M. (2006) Linking predation risk and forage to ungulate population dynamics. University of Alberta. Appendix 2A: Landcover mapping for the Ya Ha Tinda elk and wolf project study area. 

McDermid, G.J., Franklin, S.E. & LeDrew, E.F. (2005) Remote sensing for large-area habitat mapping. Progress in Physical Geography, 29, 449-474.

Wegmann, M., Leutner, B. & Dech, S. (2016) Remote Sensing and GIS for Ecologists using Open Source Software, Pelagic Publishers, Exeter, UK.

## Loading and Manipulating Landcover Data
```{r}
setwd("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/lab4/landcover/")
landcover<-raster("landcover")
landcover<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/lab4/landcover/landcover")
image(landcover, col=rainbow(16))
#str(landcover)
landcover@data@attributes
```

Note that this 'legend' is what we want to keep track of as we transform the data to a GTiff below.
```{r}
landcover@crs@projargs
extent(landcover)
landcover
#### now lets write this as a TIFF format (easier to use) to be the same as all other raster stack objects
#### note you can sometime get errors creating a raster stack out of different kinds of rasters
setwd("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/lab4/new/")  
writeRaster(landcover, "landcover16.tif", "GTiff", overwrite = TRUE)
landcover16 <- raster("landcover16.tif") # bringing it back in
str(landcover16@data@attributes)
```

But now note that we have semmingly lost the HABITATTYPE field which did not get transformed through writeRaster.  Therefore we should go back to the original landcover model, and remap the same Habitat Type field.  This is fairly common problem in dealing with ArcGIS data files.
```{r}
data1 <- data.frame(landcover@data@attributes[[1]][2:3])
names(landcover16@data@attributes[[1]])[2]<-"COUNT"
landcover16@data@attributes <- merge(landcover16@data@attributes, data1, by="COUNT")
landcover16@data@attributes<-landcover16@data@attributes[c(2,1,3)]
landcover16@data@attributes
```
Note the presence of clouds, rocks, ice, water - non vegetated categories.  Clouds in particular are a nuisance we will have to deal with later. 

First, lets explore some graphing options to overlay some of our previous wolf datasets over this landcover classification, and experiment with changing the colors of the landcover categories. 
```{r}
wolfyht<-shapefile("wolfyht.shp")
plot(landcover16, col=rainbow(16))
plot(wolfyht, add=TRUE, type="p", color = "gray25", pch=19, cex = 0.75)
extent(landcover16) 
```
Note that this extent is different than below.  But now, lets make a second plot zooming into a specific area of the Red Deer pack showing one way how to 'clip' the extent to a zoomed in area. 
```{r}
## lets make a second plot zooming into a specific area of the Red Deer pack
yht.raster <- raster()
extent(yht.raster) <- c(xmin=570000, xmax=600000, ymin=5720000, ymax=5740000) 	
plot(landcover16, col=rainbow(16), ext=yht.raster)
legend("topleft", legend = c("Open Conifer", "Mod. Conifer", "Closed Conifer", "Deciduous", "Mixed", "Regen", "Herb", "Shrub", "Water", "Rock-Ice", "Cloud", "Burn-Forest", "Burn-Grassland", "Burn-Shrub", "Alpine Herb", "Alpine Shrub"), fill = rainbow(16), cex=0.75)
plot(wolfyht, add=TRUE, type="p", color = "gray25", pch=19)

```

And next, make a zoomed in model of the elk prey layer from Lab 1. This is the first of our previously used GIS layers we will bring in from Lab 1 today.  Keep all your GIS files from Lab 1 handy. 
```{r}
bv.raster <- raster()
extent(bv.raster) <- c(xmin=560000, xmax=600000, ymin=5660000, ymax=5690000) 
elk_w<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/elk_w2.tif")
plot(elk_w, col=heat.colors(7), ext=bv.raster)
legend("topleft", legend = c("1", "2", "3", "4", "5", "6", "7"), fill = rainbow(16), cex=0.75)
plot(wolfyht, add=TRUE, type="p", color = "gray25", pch=19)

```

Review the different extents between the elk_w and landcover16 models
```{r}
extent(elk_w)
#res(elk_w) ## this was also used to check the resolutions were the same, which they were
extent(landcover16)
#res(landcover16)
```

## Aligning Different Extents in Raster Data
Recall that we then have to reset the extent to be the same before we can create a Raster Stack for extracting this landcover covariate again
```{r}
mask.raster <- raster()
extent(mask.raster) <- c(xmin=443680.6, xmax=650430.4, ymin=5618405, ymax=5789236) 	
res(mask.raster) = 30
#match projection to elc_habitat shapefile
projection(mask.raster)<- "+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
#set all values of mask.raster to zero
mask.raster[]<-0
```

Next, we need to resample the landcover16 model using the nerest neighbor method to have the same raster extent as our 'mask'. This will take several minutes of system time.  Note here we are resampling to nearest neighbor to preseve the integer value - if you do this using the bilinear resampling you get double format numbers (i.e., not integer values).  Learn more about the format of resampling in resample using:
```
?resample
```
which actually isn't that helpful. A more helpful explanation and demonstration of the difference between 
[link](https://www.nceas.ucsb.edu/scicomp/usecases/resamplerasterimages)

Resampling Landcover. 
```{r}
landcover2<-resample(landcover16, mask.raster, method="ngb") 
extent(landcover2)
```
Now the landcovers are the same.  Next we will bring in some of the previously developed continuous raster layers to continue making our consistent raster brick stack.

## Bringing in the Distance to High Human Access layer - see Lab 2 section 1b. 
```{r}
setwd("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/")
disthhu<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/DistFromHighHumanAccess2.tif")
plot(disthhu)
extent(disthhu)
```
We also need to resample this to exactly match our extent. This time we will use the bilinear interpolation because this is a continuous variable, not a list of categories such as in the landcover resampling. So - with continuous variables, bilinear interpolation is just fine.   Also note this will take a few minutes. 
```{r}
disthhu2<-resample(disthhu, mask.raster, method="bilinear")
extent(disthhu2)
```

## Re-extracting both spatial data frame
Lets bring in all the data from our original lab 1 data - where ever you still have these data, and continue to merge these. 
```{r}
setwd("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/")
deer_w<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/deer_w2.tif")
moose_w<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/moose_w2.tif")
#elk_w<-raster("elk_w2.tif") # already brought in above
sheep_w<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/sheep_w2.tif")
goat_w<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/goat_w2.tif")
wolf_w<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/wolf_w2.tif")
## Note the next two layers should already be resampled
elevation2<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/Elevation2.tif") #resampled
disthumanaccess2<-raster("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/Lab1_rintro/Lab1_data/DistFromHumanAccess2.tif") #resampled
```

## Creating a Raster Stack  
This will create a raster stack for sampling; all rasters in the same raster staack must have same extent and resolution. Otherwise, you get this error message:
```{r}
  #all_rasters<-stack(deer_w, moose_w, elk_w, sheep_w, goat_w, wolf_w, elevation2, disthumanaccess2, landcover16)
#Error in compareRaster(x) : different extent
```
Note the problem of different extents in using our landcover16 model BEFORE we reprojected it. In the hashed out text above I show the error you get if you used different extents in the raster list. 
```{r}
all_rasters<-stack(deer_w, moose_w, elk_w, sheep_w, goat_w, wolf_w,elevation2, disthumanaccess2, disthhu2, landcover2)
names(all_rasters)
```
Note that when we created the raster stack with the new, resampled landcover2, we did not get an error message. 

Now we can plot all rasters in our raster stack very easily. 
```{r}
plot(all_rasters)
```
This shows us that while the extents are now the same, there are different 'real' extents for many of the differnet GIS layers. This is something we will have to address later. 

## Re-Running Lab 2 from Source
Next we are going to re-extract covariate values for the wolf used and available datasets based on the Kernel density estimate from Lab 2. Recall that first we use the rd.data and rd.avail datasets which were a spatialDataPointsFrame needed from Lab 2. 

Instead of going all the way back to lab 2 and redoing everything again, we are going to use SOURCE as a command to re-run a trimmed down set of commands from Lab 2 to re-extract the rd.data, rd.avail, bv.data, and bv.avail data. Note also that I 'fixed' the random generation in the spsample by using the set.seed(11) command which ensures we all should get the same results. Furthermore, we really could do rd.data and bv.data with the steps below, but it is the AVAILABILITY datasets we need to restimate.  To learn more about sourcing from Script, 
```
?source
```
We are going to have to make sure our working directory in the Lab2NeededforLab4.R file is correctly pointed to where we have the wolfyht.shp file (in Lab 4/new)

```{r}
source("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/lab4/new/Lab2NeededforLab4.R", verbose = FALSE)
```

Now look at your R objects and see that indeed, you now have rd.data, bv.data, etc. re-estimated from lab 2 to re-extract. Cool!
```{r}
rd.data<-wolfyht[wolfyht@data$Pack=="Red Deer",]
cov.outRD<-extract(all_rasters, rd.data) 

#Extract covariate values for available points
cov.availRD<-extract(all_rasters, rd.avail)

#Extract covariate values for Bow valley wolf data
bv.data<-wolfyht[wolfyht@data$Pack=="Bow valley",]
cov.outBV<-extract(all_rasters, bv.data)

#Extract covariate values for available points
cov.availBV<-extract(all_rasters, bv.avail)
```

## Attaching spatial X, Y data to Used and Available data (visualization, etc)
It is _OFTEN VERY_ useful to have X, Y locations associated with the different spatial datasets attach coordinates for red deer pack used points . Here we go back to Lab 2 Objective 4 and after we have creted the cov.outRD spatialPointsDataFrame object, we create a new object with X, Y
(Note here I supressed display of all these steps as they just repeat lab2). 
```{r, include = FALSE}
head(rd.data@coords)

## Red Deer Pack
cov.outRD2<-cbind(cov.outRD, coordinates(rd.data)[,1],coordinates(rd.data)[,2])
#set column names for coordinates
colnames(cov.outRD2)[11:12] <- c("EASTING","NORTHING")
#attach coordinates for red deer pack available points
cov.availRD2<-cbind(cov.availRD, coordinates(rd.avail)[,1],coordinates(rd.avail)[,2])
#set column names for coordinates
colnames(cov.availRD2)[11:12] <- c("EASTING","NORTHING")
#head(cov.outRD2)

#attach coorvinates for bow valley pack used points
cov.outBV2<-cbind(cov.outBV, coordinates(bv.data)[,1],coordinates(bv.data)[,2])
#set column names for coordinates
colnames(cov.outBV2)[11:12] <- c("EASTING","NORTHING")
#attach coobvinates for bow valley pack available points
cov.availBV2<-cbind(cov.availBV, coordinates(bv.avail)[,1],coordinates(bv.avail)[,2])
#set column names for coordinates
colnames(cov.availBV2)[11:12] <- c("EASTING","NORTHING")
#head(cov.outBV2)

## now lets combine the USED datasets again
## now lets combine them again
rdused <- as.data.frame(cov.outRD2)
rdused$pack <- c("Red Deer")
#str(rdused)

## repeat for Bow Valley pack
bvused <- as.data.frame(cov.outBV2)
bvused$pack <- c("Bow Valley")
#str(bvused)

## merge the two USED samples together
wolfused <- rbind(rdused, bvused)
## and for next week, lets add a new column for a 1=used 0 = avail
wolfused$used <- 1
#head(wolfused)

## now lets combine the AVAIL datasets again 
rdavail <- as.data.frame(cov.availRD2)
rdavail$pack <- c("Red Deer")
#str(rdavail)

## repeat for Bow Valley pack
bvavail <- as.data.frame(cov.availBV2)
bvavail$pack <- c("Bow Valley")
#str(bvavail)

## merge the two availability samples together
wolfavail <- rbind(rdavail, bvavail)
## and for next week, lets add a new column for a 1=used 0 = avail
wolfavail$used <- 0
#head(wolfavail)
```

Finally, we will Merge the wolf used and avail samples together for the KDE availability estimator
```{r}
wolfkde <- rbind(wolfused, wolfavail)
#str(wolfkde)
table(wolfkde$used, wolfkde$pack)
wolfkde$usedFactor <- factor(wolfkde$used, labels=c('0','1'))
write.table(wolfkde, file = "/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/lab4/new/wolfkde.csv", row.names=FALSE, na="", col.names=TRUE, sep=",")
wolfkde <- read.csv("/Users/mark.hebblewhite/Box Sync/Teaching/UofMcourses/WILD562/Spring2019/Labs/lab4/new/wolfkde.csv", sep=",")
```

Now we can make a single nice plot of the X and Y locations by Used by Pack, where used locations are a bright blue, and available locations are dark blue. 
```{r}
ggplot(wolfkde, aes(x=EASTING, y = NORTHING, color=usedFactor)) + geom_point() + stat_density2d() + facet_grid(pack ~ ., scales="free")

# or, Facetting by Used
ggplot(wolfkde, aes(x=EASTING, y = NORTHING)) + geom_point() + stat_density2d() + facet_grid(pack ~ usedFactor, scales="free")

```

# Objective 2.0  Univariate Model-fitting 
These are a repeat of the commands from lab 3, but here I will show you how to extract covariate tables from multiple models. Note in the script I also did this for Bv and rd wolf packs. We will just keep these handy for later, as today's focus is on categorical analysis of landcover. But, it might be handy to relate certain landcover types with certain prey (e.g., alpine and sheep/goats) for discussion. 
```{r}
### First for all packs
elev <- glm(used ~ Elevation2, family=binomial(logit), data=wolfkde)
distacc <- glm(used ~ DistFromHumanAccess2, family=binomial(logit), data=wolfkde)
disthha <- glm(used ~ DistFromHighHumanAccess2, family=binomial(logit), data=wolfkde)
sheep <- glm(used ~ sheep_w2, family=binomial(logit), data=wolfkde)
goat <- glm(used ~ goat_w2, family=binomial(logit), data=wolfkde)
elk <- glm(used ~ elk_w2, family=binomial(logit), data=wolfkde)
moose <- glm(used ~ moose_w2, family=binomial(logit), data=wolfkde)
deer <- glm(used ~ deer_w2, family=binomial(logit), data=wolfkde)

# creating tables of B, SE
# First grab all of the estimates and standard errors
models = rbind(summary(elev)$coefficients[,1:2], summary(disthha)$coefficients[,1:2], summary(distacc)$coefficients[,1:2], summary(sheep)$coefficients[,1:2], summary(goat)$coefficients[,1:2], summary(elk)$coefficients[,1:2], summary(moose)$coefficients[,1:2], summary(deer)$coefficients[,1:2])
# Name your models
modelnames = c("elev","disthha", "distacc", "sheep", "goat", "elk", "moose", "deer")
# Now put all of your estimates in a pretty table with names that you'll remember!
estimates.all = matrix(models, nrow=2*length(modelnames), ncol=2, dimnames = list(paste(rep(modelnames, each=2),c("intercept", "coefficient")), c("B", "SE")))
estimates.all
```

# Objective 3.0  Categorical Resource Selection Functions

The first thing we need to do is add a column with the name habitat type (landcover) in it to help us keep track of what the different landcover codes mean.
```{r}
levels(wolfkde$landcover16) ## see, all we have is landcover code

wolfkde$habitatType = ifelse(wolfkde$landcover16 == 0, "NA", 
                            ifelse(wolfkde$landcover16 == 1, "Open Conifer", 
                            ifelse(wolfkde$landcover16 == 2, "Moderate Conifer", 
                            ifelse(wolfkde$landcover16 == 3, "Closed Conifer", 
                            ifelse(wolfkde$landcover16 == 4, "Deciduous", 
                            ifelse(wolfkde$landcover16 == 5, "Mixed", 
                            ifelse(wolfkde$landcover16 == 6, "Regen", 
                            ifelse(wolfkde$landcover16 == 7, "Herbaceous",                 
                            ifelse(wolfkde$landcover16 == 8, "Shrub",                       
                            ifelse(wolfkde$landcover16 == 9, "Water", 
                            ifelse(wolfkde$landcover16 == 10, "Rock-Ice", 
                            ifelse(wolfkde$landcover16 == 11, "Cloud", 
                            ifelse(wolfkde$landcover16 == 12, "Burn-Forest",               
                            ifelse(wolfkde$landcover16 == 13, "Burn-Grassland", 
                            ifelse(wolfkde$landcover16 == 14, "Burn-Shrub", 
                            ifelse(wolfkde$landcover16 == 15, "Alpine Herb", "Alpine Shrub"))))))))))))))))

table(wolfkde$landcover16, wolfkde$used)
```
Note: that each of you _may_ get slightly different AVAILABILITIES (especially if we did not set.seed(11) because of your own random sampling of availability. This is particularily problematic for rare landcover types like 4 (decid), 6 (regen), clouds (11), etc. Thus for some of you, your table may look slightly different and you will have to keep track of landcover types yourself. 

Alternatively, redo the analyses with the set.seed(11) code in the Lab2NeededforLab5.R code that I have now updated. 

Lets this graph shows the differences in the proportions between used and available for both packs for landcover type
```{r}
table(wolfkde$habitatType, wolfkde$usedFactor)
ggplot(wolfkde, aes(x=landcover16, y=..density.., fill = used)) +geom_histogram(binwidth = 1) + facet_grid(used~.)

```

What should we do about the NA or Clouds? We will have to discuss what to do with NA's and Cloud? For now, we will decide to remove clouds as missing data
```{r}
wolfkde2 <- wolfkde[wolfkde$landcover16 != 11, ]
wolfkde3 <-wolfkde2[wolfkde2$landcover16 != 0, ]
table(wolfkde3$habitatType, wolfkde3$usedFactor)
## see we have removed clouds and NA's
```

## Legend File
Next we will create a 'legend' file (names.m) to help us keep track of contrasts
```{r}
names.m = data.frame(unique(wolfkde3$landcover16),unique(wolfkde3$habitatType))
# Now I put it order
names.m = names.m[order(names.m)[1:15],]
names.m
# Define a factor variable, landcov.f, # the sorted table makes defining the names of your factor level easy!

wolfkde3$landcov.f = factor(wolfkde3$landcover16,labels = names.m$unique.wolfkde3.habitatType)

#Note that there are many alternative ways of defining your landcover/habitattype 
# as a factor. This method seemed most explicit in terms of defining the design matrix
table(wolfkde3$landcov.f, wolfkde3$usedFactor)
table(wolfkde3$landcov.f, wolfkde3$landcover16)
 
```

## Univariate Selection Ratio's
First we will estimate Manly's selection ratio by comparing the ratio of used and available locations to each other, and taking the natural logarithm of those in R. Manly et al. (2002) Chapter 1 Readings provide an overview and methodology for this kind of design, relying on the calculation of selection ratios:

$$\omega_i = \frac {\upsilon_i}{\alpha_i}$$
where $\upsilon_i$ is the proportion of use of the habitat class __i__ and $\alpha_i$ is the proportion of availability of this habitat class __i__. Here, there are 1... __j__ habitat categories. 

Note that these ratios may be scaled so that their sum is equal to 1, that is:
$$\beta_i = \frac{\omega_i}{\sum_{i=1}^j \omega_j}$$
where $\beta_j$ is said to be the Scaled Selectivity Coefficient for habitat class __i__.  This has the interpretation of being the estimated probability that a category __i__ resource unit would be selected if each category from 1... __j__ was equally available. 

Note that it is customary to take the natural logarithmic transformation of the $\omega_i$ to make the selectivity index symmetric for the same amount of increase or decrease of use or availability. This is a similar property in population ecology to the difference between lambda, the ratio of two population sizes which estimates the absolute growth rate, to little r, or intrinsic population growth rate, which measures the relative growth rate. So we have 
$$\ln(\omega_j) = ln(\frac {\upsilon_j}{\alpha_j})$$
This is often referred to as the ln of the selection ratio, or Manly's Selection index. 


We will now calculate selectivity statistics, both untransformed (which we can call the selection ratio) and ln-transformed selectivity index using our data frame of the availability and use by wolves for our ~ 16 'landcover' types in Banff National Park. To do this, we have to use the random points and used points to represent the proportional use $\upsilon_j$and availability $\alpha_i$components of the equations above, respectively. 

```{r}
table(wolfkde3$habitatType, wolfkde3$usedFactor)
landcovSelection <- table(wolfkde3$habitatType, wolfkde3$usedFactor)
landcovSelection2 <- as.data.frame.matrix(landcovSelection)
colnames(landcovSelection2)[1:2] <- c("avail","used")
## Calculate Proportional Availability
landcovSelection2$pUse <- landcovSelection2$used /413
landcovSelection2$pAvail <- landcovSelection2$avail /1996 # not 2000 because of censored cloud and NA's. 

## Now, lets calculate the selection ratio using the proportions of use and availability
landcovSelection2$selection <- landcovSelection2$pUse / landcovSelection2$pAvail

## compare the two - they are absolutely LINEARLY related, but, only the ratio of pUse/pAvail is interpretable as a selection ratio about 1.0. 
## NExt, lets calculate the selection ratio using JUST the # of locations (incorrect)
landcovSelection2$selectionN <- landcovSelection2$used / landcovSelection2$avail
plot(landcovSelection2$selection, landcovSelection2$selectionN)

## LEts take a look, this is the selection ratio, the ratio of the proportion used to the prortion available from our first equation above. 
landcovSelection2
## Next we take the natural logarithm, ln() which in R is represented by log()
landcovSelection2$lnSelection <- log(landcovSelection2$selection)

## Lets make a new column of habitatType
landcovSelection2$landcoverType <- c("Alpine Herb", "Alpine Shrub", "Burn-Forest", "Burn-Grassland", "Burn-Shrub", "Closed Conifer", "Deciduous", "Herbaceous", "Mixed", "Moderate Conifer" ,"Open Conifer", "Regen", "Rock-Ice", "Shrub", "Water")
                          

## lets make a plot of the Manly (ln) Selectivity Coefficients
ggplot(data=landcovSelection2, aes(x=landcoverType, y = lnSelection)) + geom_point(size=4) + theme(axis.text.x = element_text(angle = 90))
```

This is a simple histogram of the Manly's ln-transformed selectivity coefficients as a function of landcover types. Why did we get the error messages about infinity??
```{r}
## it might be handy to save this
write.table(landcovSelection2, "wolfselection.csv", sep=",", row.names = TRUE, col.names=TRUE)
str(landcovSelection2)
```
How do the selection ratio and Selectivity coefficient relate to each other??? Lets make ggplots of the Selectivity and Ln Selectivity Coefficients
```{r}
## Selection ratio
ggplot(landcovSelection2, aes(x=landcoverType, y = selection)) + geom_bar(stat="Identity") + theme(axis.text.x = element_text(angle = 90))
## Ln-Selection Ratio
ggplot(landcovSelection2, aes(x=landcoverType, y = lnSelection)) + 
geom_bar(stat="Identity") + theme(axis.text.x = element_text(angle = 90))
```

What is the relationship between the selection ratio and the Ln-Selection Ratio?
```{r}
## Fancier ggplot
ggplot(landcovSelection2, aes(x=selection, y = lnSelection)) + stat_smooth()
```
Discussion: why is the relationship between the seleciton ratio and the Ln selection ration curvilinear like this?


## Selection Ratio's in adehabitatHS
Next, we will use the adehabitat package functions to estimate selection ratio's for proportional availability and use data following Manly et al. 2003.  We will use the example of Elk (Manly et al., 2003, p.62). This is a classic study based on the original work of my predecessor here at the University of Montana, C.Les Marcum, and worth a moment to reflect on. 

This is amongst the first statistical test for whether or not habitat selection occurs in animals. This method assumes: (i) independence between animals, and (ii) all animals are selecting habitat in the same way. Moreover, the overall hypothesis tested is that the use of resource categories differs from random availability, thats it.  Since the 1980's we have learned that this is often not a very interesting hypothesis to test, since we know it true that animals almost always use resources in a selective way, nonetheless, this is where the field started. 

__References__
Marcum, C.L. & Loftsgaarden, D.O. (1980) A nonmapping technique for studying habitat preferences. Journal of Wildlife Management, 44, 963-968.

This shows examples with the older adehabitat package, note these are now part of adehabitatHS
[adehabitat package](https://rdrr.io/cran/adehabitat/man/wi.html) 
[adehabitatHS vignette/demo](http://www2.uaem.mx/r-mirror/web/packages/adehabitatHS/vignettes/adehabitatHS.pdf) 
```{r}
## Estimated available proportions on design I data
elk.avail <- c(15, 61, 84, 40)
elk.used <- c(3, 90, 181, 51)
names(elk.used) <- c("0%", "1-25%", "26-75%", ">75%")
names(elk.avail) <- names(elk.used)
## Computation of wi
(wiRatio <- widesI(elk.used, elk.avail, avknown=FALSE))

## plot the values of the selection ratios
plot(wiRatio)
```

# Objective 4.  Categorical Logistic Regression

Lastly, we will learn about analyzing categorical variables using a new approach compared to categories. To learn more about how R uses contrasts to set the design matrix in any linear model search for help on contrast matrices
```
?contrast
```
Even though this may seem 'new' if you have ever done ANOVA (a linear model) in R, you have used contrast matrices to do so.  
```{r}
contrasts(wolfkde3$landcov.f) = contr.treatment(15) ## note here also that in my case I had 15 landcover types
# To see the design matrix assigned
attributes(wolfkde3$landcov.f)
levels(wolfkde3$landcov.f)
```

Note that while we have cleaned up the clouds and NA's, what should we do about Burned-Grassland, Burned-Herbaceous and Burn-Forests? Recall that these 3 landcover types had some categories with 0 observed wolf uses in them, so we coudl reclassify them all as 'burned'. We will return to this in a minute. Here, checking above, we see that 11, 12, and 13 are all burns. 
```{r}
levels(wolfkde3$landcov.f)[11:13] = "Burn"
## note this then reduces us from 15 to 13 categories
contrasts(wolfkde3$landcov.f) = contr.treatment(13)
attributes(wolfkde3$landcov.f)
```
Note how the design matrix has collapsed burn into one category? What other categories should we consider? Perhaps Alpine? 

## Incorrectly Treating Landcover as Continuous
First, we will use Logistic regression incorectly analyzing treating landcover16 as a continuous covariate
```{r}
naive.nf = glm(used~landcover16,data=wolfkde3, family=binomial(logit))
summary(naive.nf)
```
We have incorrectly treated landcover code (1 to 16) as a continuous covariate! We will analyze it correctly specifying in R that it is actually a categorical variable using the I~(landcover.f) Interaction expansion. But first, to see how this works, we will do it JUST for one landcover type, in this case, Open Conifer. 
```{r}
oc = glm(used~I(landcov.f=="Open Conifer"),data=wolfkde3, family = binomial(logit))
summary(oc)
#str(summary(oc))
```
Now lets manually evaluate the predicted probability of a wolf used location occuring in Open Conifer
```{r}
exp(-1.622+0.711*1)/(1+exp(-1.622+0.711*1))
## now compare to the probability of wolf use in non-conifer landcovers ?
exp(-1.622+0.711*0)/(1+exp(-1.622+0.711*0))
```
Discussion: How do these probabilities of use in open conifer, and of non-use of open conifer compare to our previous ratio's of used to available from the Manly selection ratio's?


# Multiple Logistic Regression example with multiple categories

Next we will fit a model with 2 landcover types, manually, and then, three, and so on until we fit all landcover types using the interaction expansion with the contrast matrix. 
```{r}
## with just open conifer and burns
ocb = glm(used~I(landcov.f=="Open Conifer")+I(landcov.f=="Burn"), data = wolfkde3, family = binomial(logit))
summary(ocb)

### and with a few more variables
conif = glm(used~I(landcov.f=="Open Conifer")+I(landcov.f=="Moderate Conifer")
                  +I(landcov.f=="Closed Conifer"), data = wolfkde3, family = binomial(logit))
summary(conif)
```
How do we interpret the intercept in each model? In model ocb the intercept is everything EXCEPT burns and open conifer.  Whereas  in the second, its everything except conifers.

##  Full model with all categories considered
```{r}
# Full model
full = glm(used~I(landcov.f), data=wolfkde3, family = binomial(logit))
summary(full)
```
Discussion: What is the intercept? Where did alpine (landcover 15) go? Why did landcover types 4 (decid), 6 (regen) and alpine- herb (12) 'blow' up? Go back and look at this table to undestand
```{r}
table(wolfkde3$landcov.f, wolfkde3$usedFactor)
```
They blew up because there was 0 used observed.  See what its trying to estimate?
```{r}
exp(-0.974 - 15.592*1)/(1+exp(-0.974 - 15.592*1)) ## these are the intercept and coefficient for deciduous
```
Which is telling us that the probability of wolves using decid is essentially 0, but with no precision (look at the SE) because its unestimable. In this case, all landcover types without observations should technically be dropped and or reclasses into the intercept category. So our options are to delete these rows of data like NA's above or Cloud or more CORRECTLY, __reclass__ categories with zero observations as equivalent to the intercept. The latter is my recommendation, but lets wait to do that 'manually' below. 

## Models Without an Intercept
This is a useful excercise to learn exactly what the intercept does in a model. Lets use the R notation to manually force no intercept in the model
```{r}
full.NoInt = glm(used~I(landcov.f) -1, data=wolfkde3, family = binomial(logit))
summary(full.NoInt)
```
Note that the model with no intercept in it keeps Open Conifer.Compare these coefficients to the coefficients with the same model but with an intercept.
How do they differ??


Now lets fit the model manually with each factor with open conifer as the intercept. Note that it is the same as the model full above and that the Intercept is now manually defined as Open Conifer
```{r}
full.model = glm(used~I(landcov.f=="Moderate Conifer")+I(landcov.f=="Closed Conifer") +I(landcov.f=="Deciduous")+I(landcov.f=="Mixed")+I(landcov.f=="Herbaceous")+I(landcov.f=="Regen")+I(landcov.f=="Shrub")+I(landcov.f=="Water")+I(landcov.f=="Rock-Ice") +I(landcov.f=="Burn")+I(landcov.f=="Alpine Herb")+I(landcov.f=="Alpine Shrub"), data = wolfkde3, family = binomial(logit))
summary(full.model)
```

# Objective 5. Changing the Reference Category
Here, we will gain an appreciation for the influence of changing the reference category on the model. To change the reference level to say Rock and ICe (9), you simply reset the contrast/design matrix, for example,
```{r}
## first recheck which # Rock-Ice is
levels(wolfkde3$landcov.f) ## Ok it is # 10

contrasts(wolfkde3$landcov.f) = contr.treatment(13, base = 10)
attributes(wolfkde3$landcov.f)
# and note that rock-ice now is 0. 

rockintercept.model = glm(used~I(landcov.f=="Moderate Conifer") +I(landcov.f=="Closed Conifer") +I(landcov.f=="Deciduous")+I(landcov.f=="Mixed")+I(landcov.f=="Herbaceous") +I(landcov.f=="Regen")+I(landcov.f=="Shrub")+I(landcov.f=="Water")+I(landcov.f=="Open Conifer")+I(landcov.f=="Burn")+I(landcov.f=="Alpine Herb")+I(landcov.f=="Alpine Shrub"), data = wolfkde3, family = binomial(logit))
summary(rockintercept.model)
```
_Discussion:_Now compare coefficients from each model with open conifer vs. Rock and Ice as the intercept models? What has changed? For an excercise, chose other reference categories on your own?

Now compare coefficients from each model with open conifer vs. Rock and Ice as the intercept models? What has changed?Make a table comparing coefficients from different models with different intercepts? Now chose other reference categories on your own?

## Manual Dummy (Indicator) Coding
In practice I find working through the Design matrix coding of R confusing. Instead, I often just create my own 'manual' dummy variables in my data frame, sometimes even beforehand in excel (gasp!). These next commands manually creating 'dummy' variables that replace using the interaction expansion used ~ I.
```{r}
wolfkde3$closedConif = ifelse(wolfkde3$habitatType == "Closed Conifer", 1, 0)
wolfkde3$modConif = ifelse(wolfkde3$habitatType == "Moderate Conifer", 1, 0)
wolfkde3$openConif = ifelse(wolfkde3$habitatType == "Open Conifer", 1, 0)
wolfkde3$decid = ifelse(wolfkde3$habitatType == "Deciduous", 1, 0)
wolfkde3$regen = ifelse(wolfkde3$habitatType == "Regen", 1, 0)
wolfkde3$mixed = ifelse(wolfkde3$habitatType == "Mixed", 1, 0)
wolfkde3$herb = ifelse(wolfkde3$habitatType == "Herbaceous", 1, 0)
wolfkde3$shrub = ifelse(wolfkde3$habitatType == "Shrub", 1, 0)
wolfkde3$water = ifelse(wolfkde3$habitatType == "Water", 1, 0)
wolfkde3$rockIce = ifelse(wolfkde3$habitatType == "Rock-Ice", 1, 0)
## note here I reclassified all burn = 1 
wolfkde3$burn = ifelse(wolfkde3$habitatType == "Burn-Grassland", 1, ifelse(wolfkde3$habitatType == "Burn-Shrub", 1, ifelse(wolfkde3$habitatType == "Burn-Forest", 1,0 )))
wolfkde3$alpineHerb = ifelse(wolfkde3$habitatType == "Alpine Herb", 1, 0)
wolfkde3$alpineShrub = ifelse(wolfkde3$habitatType == "Alpine Shrub", 1, 0)

head(wolfkde3)
```
Note now that the design matrix is manually set in the data.frame. This is inefficient, but might be easier to keep track of. You can also easily reclassify categories now, but you have to _mentally_ keep track of the unit-sum constraint to ensure your model is identifiable with respect to the categorical variables. i.e., you do not add everthing! 

For example, here we can easily create a new 'alpine' variable by adding alpine herb and alpine shrub. 
```{r}
wolfkde3$alpine = wolfkde3$alpineHerb + wolfkde3$alpineShrub
```

Refitting model with Open Conifer as the intercept and alpine/burn pooled
```{r}
oc.intercept.model = glm(used~closedConif + modConif + decid+ regen+mixed+herb+water+rockIce+burn+alpine, data = wolfkde3, family = binomial(logit))
summary(oc.intercept.model)

### refitting model with just Alpine and Rock and Ice as the intercept
rockintercept.alpine.model = glm(used~closedConif + openConif + modConif + decid+ regen+mixed+herb+water+burn+alpine, data = wolfkde3, family = binomial(logit))
summary(rockintercept.alpine.model)

### refitting model manually dropping Decid and Regen - where do they no go?
rock.alpine.regen.decid.intercept.model = glm(used~closedConif + openConif + modConif + mixed+herb+water+burn+alpine, data = wolfkde3, family = binomial(logit))
summary(rock.alpine.regen.decid.intercept.model)
```

## Comparing coefficients from two different models with different intercepts
I adopt the code from section 2.0 above to pull out all the coefficients and SE's and put them in one long table
```{r}
rockintercept.alpine.model.df <- data.frame(summary(rockintercept.alpine.model)$coefficients[,1:2])
oc.intercept.model.df <- data.frame(summary(oc.intercept.model)$coefficients[,1:2])
coef.table <- rbind(rockintercept.alpine.model.df,oc.intercept.model.df)
coef.table$habitatType <- c(row.names((summary(rockintercept.alpine.model)$coefficients[,1:2])),row.names(summary(oc.intercept.model)$coefficients[,1:2]))
coef.table$habitatType[1] <- "rockIce"
coef.table$habitatType[12] <- "openConif"
coef.table$model <-c(rep("Open Conif Intercept",11),rep( "RockIce Intercept",11))
coef.table
```
Now use this table to compare the ABSOLUTE differences say between burn and alpine in both models. In the oc.model the B coefficient for Burn = 0.29 and Alpine = -3.002 an absolute differences of 3.29. In the rock.model the B coefficient for Burn = 2.2 and Alpine is -1.086, an absolute difference of 3.29 -
the same! Why is this?


Now lets make a figure of the Beta coefficients (you can figure out how to add SE's yourself :)
```{r}
ggplot(coef.table, aes(x=habitatType, y=Estimate, colour=model)) + geom_point(size = 5) + theme(axis.text.x = element_text(angle = 90))
```
This figure tells us that RELATIVELY nothing has changed, only where the coefficients are relative to the yAxis

# Homework 4

LAB 4 – ASSIGNMENT 
DUE IN CLASS Tuesday February 12th, 2019

Answer the following questions in your lab report, feeling free to use TABLES and FIGURES properly labeled and in JWM format.  Feel free to re-use (revised If I made suggestions) introductions, study areas, basic methods from previous labs, and focus just on the goal of summarizing what the best statistical model for categorical landcover selection is. 

1.	What would be you’re a-priori hypothesis for this lab? In other words, based on previous literature, and previous analyses you’ve done, what landcover types would you expect wolves to select? In the discussion, answer whether the results of your study compare broadly well to previous studies (Oakleaf et al. 2006, Hebblewhite et al. 2005 – OIKOS), etc.??  How do you relate selection for landcover to previous results of selection for habitat suitability indices for ungulates? Report differences in landcover between packs as well .

2.	What is your ‘best’ model for categorical habitat types? What are the effects of landcover type on wolves? Be sure to write the linear part of the logistic regression formula for the top model in the results, and for this lab, present the selection data in both tabular and categorical form.  

3.	Discuss what the effects of changing the reference category in your RSF say, from closed conifer to rock and ice, does to your results? As an appendix, present a figure and table of the results from one other analysis with a difference reference category.

4. What is the relationship between the selection ratio, the ln(selection ratio), and the beta coefficients estimated from a logistic regression equation? 
